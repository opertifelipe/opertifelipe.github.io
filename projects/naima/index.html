<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Naima Lab | Felipe Operti</title> <meta name="author" content="Felipe Operti"> <meta name="description" content="Prototype for Language Model Fine-Tuning and Optimization"> <meta name="keywords" content="AI, NLP, MachineLearning, DeepLearing, SoftwareEngineering"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="opertifelipe.github.io/projects/naima/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Felipe </span><span class="font-weight-bold">Operti</span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/contacts/">contacts</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Naima Lab</h1> <p class="post-description">Prototype for Language Model Fine-Tuning and Optimization</p> </header> <article> <h2 id="description">Description</h2> <p>Naima Lab is a cutting-edge prototype designed to explore and demonstrate the fine-tuning and optimization of large language models (LLMs) for various natural language processing (NLP) tasks. This project serves as a proof of concept, showcasing the integration of state-of-the-art tools and techniques to streamline the process of adapting pre-trained language models to specific use cases. While still in its early stages, Naima Lab provides a robust foundation for experimenting with advanced NLP workflows and methodologies.</p> <h2 id="key-features">Key Features</h2> <ol> <li> <p><strong>Fine-Tuning Large Language Models</strong><br> Naima Lab enables users to fine-tune pre-trained LLMs, such as Qwen, Llama, and Phi models, using custom datasets. The project leverages advanced frameworks like Hugging Face Transformers and Unsloth to optimize the training process, ensuring efficient resource utilization and high-quality results.</p> </li> <li> <p><strong>Configurable Training Pipelines</strong><br> The project supports highly customizable training pipelines through YAML configuration files. Users can define parameters such as model architecture, sequence length, learning rate, batch size, and evaluation strategies, making it easy to adapt the prototype to different tasks and datasets.</p> </li> <li> <p><strong>Support for Lightweight Training</strong><br> Naima Lab incorporates techniques like 4-bit quantization and LoRA (Low-Rank Adaptation) to reduce memory usage and computational overhead during training. These optimizations make it possible to fine-tune large models on resource-constrained hardware.</p> </li> <li> <p><strong>Dataset Preparation and Standardization</strong><br> The prototype includes utilities for preparing and standardizing datasets, ensuring compatibility with the fine-tuning process. It supports conversational datasets, such as ShareGPT-style data, and provides tools for formatting prompts and responses.</p> </li> <li> <p><strong>Integration with Popular Frameworks</strong><br> Naima Lab integrates seamlessly with popular NLP frameworks like LangChain and Hugging Face, allowing users to leverage pre-built components for tasks such as embeddings generation, chat-based interactions, and zero-shot classification.</p> </li> <li> <p><strong>Command-Line Interface (CLI)</strong><br> The project features a user-friendly CLI built with Typer, enabling users to execute fine-tuning workflows with simple commands. This interface abstracts the complexity of the underlying code, making it accessible to both researchers and developers.</p> </li> <li> <p><strong>Prototype-Only Scope</strong><br> As a prototype, Naima Lab is not intended for production use. Instead, it serves as a sandbox for experimenting with LLM fine-tuning techniques, providing valuable insights and learnings for future development.</p> </li> </ol> <h2 id="use-cases">Use Cases</h2> <ul> <li> <strong>Custom Chatbots</strong>: Fine-tune LLMs to create domain-specific conversational agents capable of understanding and responding to user queries with high accuracy.</li> <li> <strong>Text Classification</strong>: Adapt pre-trained models for tasks like sentiment analysis, topic classification, and intent detection.</li> <li> <strong>Content Generation</strong>: Train models to generate high-quality text for applications such as marketing, education, and creative writing.</li> <li> <strong>Research and Experimentation</strong>: Serve as a platform for exploring new techniques in LLM fine-tuning and optimization.</li> </ul> <h2 id="limitations">Limitations</h2> <p>As a prototype, Naima Lab is not optimized for large-scale production deployments. It is designed for experimentation and learning, and users may encounter limitations in scalability, performance, and feature completeness. Future iterations of the project may address these limitations based on feedback and insights gained during this phase.</p> <h2 id="conclusion">Conclusion</h2> <p>Naima Lab represents an exciting step forward in the field of NLP, providing a flexible and powerful platform for fine-tuning large language models. While it is currently a prototype, the project demonstrates the potential of combining state-of-the-art tools and techniques to unlock new possibilities in language model customization and application. Whether you’re a researcher, developer, or enthusiast, Naima Lab offers a glimpse into the future of NLP innovation.</p> <p><a href="https://github.com/opertifelipe/naima-lab" rel="external nofollow noopener" target="_blank">Github</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Felipe Operti. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>